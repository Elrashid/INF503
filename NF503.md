---
markmap:
  initialExpandLevel: 2
---



# NF503_SEP2023

## Week01_Lectures 0
### Course Overview
#### Introduction to Computational Linguistics
##### Module Coordinator Information
##### Course Audience
#### Course Details
##### Duration and Schedule
##### Location and Materials
##### Classroom Interaction and Expectations
#### Course Description
##### Introductory Course Elements
##### Theoretical and Practical Aspects
#### Topics Covered
##### Introduction to NLP and Tools
##### Syntactic Analysis and Parsing Techniques
##### Evaluation and Applications of NLP
#### Assessment Information
##### Late Submission Policy
##### Grading System
#### Textbooks and Resources
##### Recommended Course Textbooks
##### Additional Reading Materials

### What is Computational Linguistics?
#### Definitions
##### Scientific Perspective
##### Technological Motivation
#### Terminology
##### Related Disciplines
#### Overall Goal
##### Automatic Systems for Language Understanding

### Ambiguity in Language
#### The Problem of Ambiguity
##### Examples of Ambiguity
##### Ambiguity Types
#### Dealing with Ambiguity
##### Disambiguation Approaches
##### Ambiguity in Pipelines

### Approaches in Computational Linguistics
#### Rule-Based Systems
##### Encoding of Linguistic Knowledge
##### Characteristics and Limitations
#### Data-Driven Systems
##### Implicit Knowledge and Methods
##### Adaptability and Data Sources
#### Comparison with Computer Languages
##### Ambiguity and Parsing Efficiency

### Applications of Computational Linguistics
#### Identification of NLP Applications
##### Knowledge about Language Structure
#### Examples of Applications
##### Machine Translation
##### Question Answering
##### Language Summarization
#### Preparation for NLP Work
##### Programming Skills and Tools
##### Academic and Writing Skills


## Week01_Lectures 1-3
### A brief History of Python
#### Invented by Guido Van Rossum (1990)
#### Named after "Monty Python's Flying Circus"
#### Originated as a scripting language for Amoeba OS
#### Influences from ABC and Modula-3
#### First release in 1991

### Goals of Python
#### Simple and powerful
#### Modular programming support
#### Emphasis on readability
#### Rapid development
#### Easy to embed and extend

### Features of Python
#### Easy to learn and use
#### Supports multiple programming paradigms
#### Automatic memory management
#### Integrates with other languages and libraries
#### Portable across platforms
#### Open source with a comprehensive standard library

### Python Installation
#### Available for Win/Mac/Unix/Linux
#### Generally easy to install
#### Python 2.3 or higher required for NLTK
#### IDLE as a development environment

### NLTK Installation
#### Visit NLTK website
#### Install Python and import NLTK
#### Use Python interpreter to download data

### Python Interpreter
#### Three ways to run Python code
##### Interactive mode
##### Through scripts (foo.py)
##### Special line in Unix/Windows environments

### Basic Python Syntax
#### Numbers and Strings
##### Atomic types and operations
#### Whitespaces and Indentation
##### Meaningful for code organization
#### Comments
##### Use of (#) and docstrings

### Assignments and Comparisons
#### Assignment bindings
##### References, not copies
#### Name management and scope
#### Accessing non-existent names
##### Results in an error
#### Multiple assignments and naming rules

### Control Flow
#### The if Statement
##### Indentation and colons
#### The while Loop
##### Condition-controlled loop
#### Nested Loops
##### Concept of nesting
#### The for Loop
##### Count-controlled loop using range

### Functions
#### Defining with def
#### No type declaration needed
#### Calling a function
##### Uses call by assignment
#### Functions without returns
##### All functions return a value, None if unspecified
#### Parameters and Argument Passing
##### Parameter usage and mutable/immutable behavior
#### Function overloading
##### Not supported in Python
  
### Lists, Tuples, Strings, & Files
#### Sequence Types
##### Lists, tuples, and strings overview
#### Operations on Sequences
##### Indexing, slicing, concatenation
#### Operations on Lists
##### List methods and characteristics
#### Tuples vs. Lists
##### Performance and features comparison
#### Strings
##### Immutability and basic operations
#### File I/O
##### Basic import and file operations


## Week02_Lectures_4-6

### Introduction to Corpus
#### What is a corpus?
##### Collection of language text
##### Linguistic data for analysis & hypotheses
#### Parameters of a corpus
##### Language type (Monolingual, Multilingual)
##### Source type (Written, Spoken, Mixed)
##### Corpus features (Size, Encoding, Annotated, Static/Monitor, Reference)
#### Why bother with corpora?
##### Expert speaker limitations
##### Objectivity and statistical evidence
##### Accessibility and updates
#### Fields where corpora are used
##### Lexicography, Language studies, Language teaching
##### Cultural studies, Psycholinguistics, Translation studies
##### Computational linguistics (e.g., speech recognition, machine translation)

### Introduction to NLTK
#### What is NLTK?
##### Set of Python modules for NLP tasks
#### NLTK and Python
##### Basic classes, standard interfaces, and implementations
##### Language data sets for complex NLP tasks
#### Examples of NLTK modules
##### Corpora with collections of texts
##### Tools for tokenization, tagging, parsing

### Corpora Operations
#### Extracting corpora content
##### Reading and handling corpora data
#### Searching and Counting
##### Finding patterns and occurrences
#### Frequency Distribution
##### Counting words/types frequency
##### N-grams and collocations
#### Pronouncing Dictionary
##### Phonetic transcriptions for words
#### WordNet
##### Synsets, lemmas, and semantic relations

### Additional Resources
#### Readings
##### Natural Language Processing With Python (NLTK Book)
#### Python Textbook
##### Practical guidance for using NLTK in Python
#### NLTK Official FAQ
##### Frequently asked questions about NLTK usage and troubleshooting




## Week03_Lectures 7

### Segmentation and Tokenization
#### Segmentation
##### Word Segmentation
###### Word tokenization issues, language considerations
##### Sentence Splitting
###### Period ambiguity, algorithms, examples
##### Paragraph and Topic Splitting
###### Breaks based on changes in topic or narrative
#### Tokenization
##### Basic Concepts
###### Definition, necessity for text processing, and languages with whitespace
##### Tokenization Challenges
###### Punctuation, hyphenated words, clitics, multiword expressions, non-segmented languages
##### Language-Specific Issues
###### German compounds, East Asian languages without spaces
#### Normalization
##### Case Folding
###### Uniform case for processing, exceptions for sentiment analysis
##### Lemmatization and Stemming
###### Morphological parsing, stemmer algorithms
##### Handling Special Cases
###### Abbreviations, acronyms, strange spellings, hyphenated words
#### Tools and Techniques
##### NLTK Tokenization and Normalization
###### Python libraries, handling HTML, use of stemmers and lemmatizers
##### Identifying Tokens and Tags
###### Importance for downstream processing, POS tagging implications
#### Reading and Resources
##### Suggested books and papers for further understanding


## Week03_Lectures 8

### Segmentation
#### Word Segmentation (Tokenization)
##### Challenges in Word Segmentation
##### Examples of Word Segmentation
#### Sentence Splitting
##### Identifying Sentence Boundaries
##### Algorithms for Sentence Splitting
#### Other Types of Segmentation
##### NP and VP Chunking
##### Named Entity Recognition
##### Clause, Paragraph, and Topic Splitting

### Tokenization
#### Basics of Tokenization
##### Definition and Necessity
##### Token vs. Type
##### Ambiguity in Segmentation
#### Tokenization Techniques
##### Simple White-Space Tokenization
##### Handling Punctuation and Special Cases
##### Tokenization in Non-Segmented Languages
#### Tokenization Challenges
##### Language Specific Issues
##### Abbreviations, Numbers, and Special Formats
##### Handling Hyphenated Words and Compounds
##### Dealing with Unusual Spellings
#### Tools and Libraries
##### Tokenization in Python with NLTK
##### HTML Text Extraction
##### Stemming and Lemmatization in NLTK

### Normalization
#### Case Folding
##### Importance of Case in Different Applications
##### Examples of Case Normalization
#### Handling Abbreviations and Acronyms
##### Complexities and Examples
##### Medical Acronyms/Abbreviations
#### Text Normalization Techniques
##### Lemmatization vs. Stemming
##### Stop Words Removal
##### Unicode and Diacritics Normalization

### Problems and Considerations in Tokenization
#### Token Identifications
##### What Counts as a Token
##### Influence on Downstream Processing
#### Tokenization and Tagging
##### Impact of Tokenization on POS Tagging
#### Reading Material
##### Suggested Books and Resources for Further Reading



## Week03_Lectures 9

### Regular Expressions
#### What are Regular Expressions?
##### Text pattern for matching substrings
##### Compact representation of string sets
#### Optionality and Repeatability
##### ? (Optional)
##### + (One or more times)
##### * (Zero or more times)
#### Quantifiers
##### Specific number of matches
##### Range of matches
#### Python Regular Expressions
##### The re module
##### Compiling regular expressions
##### RegexObject Methods
##### Tokenizing with RE

### Special characters and meanings
#### Special characters
##### . (dot), * (asterisk), \ (backslash)
#### Positional Matching
##### ^ (start of string), $ (end of string)
#### Character class
##### [aeiou] (vowel class), [0-9] (digit class)
#### Negative Character class
##### [^0-9] (excluding digits)

### Python Regular Expressions
#### The re module
##### Compilation and matching methods
##### Regular expression objects
#### Compiling regular expressions
##### re.compile() function
##### Dealing with the backslash plague
#### RegexObject Methods
##### match(), search(), finditer(), findall()

### Tokenization with Regular Expressions
#### Regex's for Tokenizing
##### Common regex patterns for tokens
#### Tokenization Examples
##### Using regex for extracting tokens
##### Handling special cases in tokens

### Summary & Readings
#### Summary of Regular Expressions
##### Review of key concepts
#### Suggested Readings
##### Jurafsky & Martin, NLTK Book, Mikheev 2002



## Week04_Lectures 10-11

### Approaches to Language Modeling
#### Grammatical Approaches
##### Rule-Based Generation
##### Application in Limited Domains
#### Statistical Approaches
##### Probability of Linguistic Events
##### General Application
##### Need for Large Text Corpora

### Fundamentals of Language Modeling
#### Goal of Language Modeling
##### Computing Sentence Probability
#### Language Model (LM)
##### Predicting Next Word Likelihood
##### Use in Various Tasks (Speech Recognition, etc.)

### N-gram Models
#### Basic Concept
##### Sequence of n Words
##### Unigrams, Bigrams, Trigrams
#### Counting N-grams
##### Word Occurrence and Frequency
#### Estimating N-gram Probabilities
##### Maximum Likelihood Estimation
##### Markov Assumptions
##### Chain Rule Application

### Practical Aspects
#### Working with Data
##### Counting Words and N-grams Using Python
#### Estimation Techniques
##### Relative Frequencies
##### Maximum Likelihood Estimates
#### Handling Computations
##### Logarithmic Calculations

### Applications of Language Models
#### Speech Recognition
##### Acoustic Model Combination
##### Weighting Word Sequences
#### Context-sensitive Spelling Correction
##### Homophones and Typos Handling
#### Sequences Ranking
##### Alternative Hypotheses Evaluation

### Additional Resources
#### Readings
##### "Speech and Language Processing" by Jurafsky and Martin
##### "Natural Language Processing with Python" by Bird, Klein, and Loper


## Week04_Lectures 12


### Parts of Speech (POS)
#### POS Tagging in NLTK
##### Basic Tagging Concepts
#### Tagging with NLTK
##### Tokenization and Tagging Example
##### Universal Tagset
##### Taggers in NLTK
###### Default Tagger
###### Regular Expression Tagger
###### Unigram Tagger
###### Bigram Tagger
##### Evaluating Taggers
##### Arabic POS Tagging Example

#### Evaluating Taggers
##### Test Set and Gold Standard
##### Computing % Correct
##### Separating Training and Testing Data
##### Cross-Validation

### Terminology
#### Tagging
##### Labels Associating Process
#### Tags
##### The Labels Themselves
#### Tag Set
##### Collection of Tags Used

### POS Examples
#### Lexical Categories
##### Syntactic Function
###### Examples of Nouns and Verbs
##### Morphological Function
###### Prefix and Suffix Examples
##### Semantic Coherence
###### Nouns as People, Places, or Things
###### Adjectives as Properties

### Significance of Parts of Speech
#### Word Prediction in NLP Tasks
##### Parsing, MT, Sentiment Analysis
#### Basis for Partial Parsing
#### Speech Synthesis and Pronunciation
#### Limits of Meaning and Word Prediction

### Closed and Open Classes
#### Closed Classes
##### Fixed Membership: Determiners, Pronouns, Prepositions
#### Open Classes
##### Continually Adding New Members: Nouns, Verbs, Adjectives, Adverbs

### Tagging Approaches
#### Rule-Based Tagging
##### Dictionary and Hand-Written Rules
#### Statistical Tagging
##### Probability Theory and Algorithms
###### Most-Frequent-Tag Algorithm
###### Conditional Probability and Tags

### Additional Readings and Resources
#### Speech and Language Processing by Jurafsky & Martin
#### Natural Language Processing with Python (NLTK Book)

## Week05_Lectures 13

### Context Free Grammars (CFGs)
#### Basics of CFGs
##### Syntax
##### Constituency
##### CFG Elements (Terminals, Non-Terminals, Rules)
#### Constituency Examples
##### Movement as a Unit (Pre-posing, Deletion)
##### Units That Carry Meaning (Substitution, Answer, Conjunct)
#### Context-Free Grammars Details
##### Terminals and Non-Terminals
##### Rules for CFGs
##### Abbreviations (S, NP, VP, PP, etc.)
#### Derivations and Parse Trees
##### Example Derivations
##### Visualization as Parse Trees
##### Trees and Labeled Bracketings

### Grammars and Languages
#### Introduction to Grammars
##### Rules and the Structure of Language
##### Grammars as Analysis or Synthesis Engines
#### Generativity of Grammars
##### String Generation and Structure Imposition
##### Example Sentences and Derivations
#### CFG as an Abstract Model
##### Formal Language Defined by CFG
##### Grammatical vs Ungrammatical Sentences

### Parsing Techniques
#### Overview
##### Importance of Parsing in Applications
##### Definition of Parsing Technique and Parser
#### Parsing with Python
##### Python's `nltk` Library Usage
##### Grammar and Lexicon Definitions
##### Building and Viewing Parse Trees

### Recursion and Coordination in CFGs
#### Recursion in Grammar
##### Direct and Indirect Recursion
##### Examples of Recursion with Sentential Complements
#### Coordination Schema
##### General Coordination in CFGs
##### Examples with NP, VP, S Coordination
#### Python and Recursive CFGs
##### Example CFGs in Python
##### RecursiveDescentParser Usage



## Week05_Lectures 14

### Parsing Techniques
#### Classical Parsing Techniques
##### Top-down Parsing
###### Never explores options that can't lead to a full parse
##### Bottom-up Parsing
###### Never explores options that don't connect to the actual sentence
#### Dynamic Programming Parsing Techniques
##### CKY (Cocke-Kasami-Younger) Algorithm
###### Requires grammar in Chomsky normal form (CNF)
#### Problems with Both Methods
##### Repeated work and efficiency

### Chomsky Normal Form (CNF)
#### Definition of CNF
##### Grammars with specific production forms
#### Converting CFG to CNF
##### Adding new start symbols
##### Removing epsilon productions
##### Removing unit productions
##### Handling longer productions

### Dynamic Programming in Parsing
#### Caching Intermediate Results
##### Critical for polynomial time parsing algorithms
#### Parsing Complexities
##### Recognition time O(n^3)
##### All parses can be exponential

### CKY Parsing Algorithm
#### Intuition and Table-Filling Strategy
##### Transforms terminals and applies rules systematically
#### Complexity and Performance
##### O(n^3) for recognition
##### Exponential for finding all parse trees
#### Parse Tree Post-Processing
##### Repairing parse tree to match original grammar

### Tools and Further Reading
#### Software for Language Processing
##### JFLAP
#### Recommended Books
##### "Speech and Language Processing" by Jurafsky & Martin
##### "Natural Language Processing with Python" by Bird, Klein, & Loper

## Week05_Lectures 15

### Ambiguity and Recursion
#### Recursion
#### Syntactic Ambiguity
##### Problematic Understanding with CFGs
#### Problem Areas for CFGs
##### Agreement
###### Number Agreement
###### Number Agreement: Verbose Alternative
##### Sub-categorization
###### Examples of Sub-categorization

### Feature Based Grammars
#### Dictionary as Feature Structures
##### Features like CAT, ORTH, REF, REL
#### Python: Lexical Productions
##### Implementation Examples
#### Python: Grammar Productions
##### Specific Production Rules

### TreeBanks
#### Definition and Purpose
##### Annotations and Guidelines
#### Penn Treebank
##### Penn Arabic Treebank (PATB) Example
##### Treebank Grammars
###### Rule Extraction
###### Flat Structures and Recursion Avoidance
#### Heads in Trees
##### Lexically Decorated Tree
##### Head Finding
#### Treebank Uses
##### Statistical Parsers
##### Corpus Linguistics

### Summary
#### Key Topics Covered
#### Recommended Readings
##### "Speech and Language Processing" Reference
##### "NLP with Python" Reference

## Week06_lectures 16-17

### Lecture: Statistical Parsing and PCFGs
#### Classical NLP Parsing
##### Problems with Coverage and Ambiguity
##### Need for Probabilistic Parsing
#### Statistical Parsing: Status
##### Success and Improvement of Statistical Parsers
##### Parsers as a Commodity Component
#### Probabilistic Context-Free Grammars (PCFGs)
##### Introduction of Probabilities to CFGs
##### Rule Probability and Estimation
##### Probabilistic CYK Algorithm
#### Parsing Applications
##### Question Answering Systems
##### Named Entity Extraction
##### Sentence Compression
##### Opinion Mining
#### Difficulties in Natural Language Understanding (NLU)
##### Ambiguous Newspaper Headlines
##### Ambiguity in Language Structure
#### The Rise of Annotated Data
##### Introduction of Penn Treebank
##### Benefits of Treebanks
#### Three Useful PCFG Tasks
##### Observation Likelihood
##### Most Likely Derivation
##### Maximum Likelihood Training
#### The Inside Algorithm
##### Computing Probabilities of Parses
##### Use in Language Modeling
#### Lexicalization of PCFGs
##### Handling Lexical Dependencies
##### Enhancing Parse Precision
#### Evaluation of Parsing
##### Parseval Metrics
##### Parsing Evaluation Using Treebanks
#### Statistical Parsing Conclusions
##### Resolution of Ambiguities
##### Learning from Treebanks
##### Lexicalization Importance
##### Comparison with Human Parsing
#### Readings and Resources
##### Jurafsky and Martin's "Speech and Language Processing"
##### Bird, Klein, and Loper's "Natural Language Processing with Python"

## Week06_lectures 18

### Full and Partial Parsing
#### Full Syntactic Parsing
##### Necessity for Semantic Analysis
##### Impractical for Many Applications
#### Problems with Full Parsing
##### Coverage and Ambiguity
##### Low Accuracy
##### Speed
#### Alternatives to Full Parsing
##### Dependency Parsing
###### Binary Relations
###### Dependency Parse
##### Partial Parsing
###### Chunking Approaches
###### More Robust and Efficient

### Dependency Grammars
#### Dependency Relations
##### Represent Syntactic Structure
##### Advantages over Phrase-Structure Parsing
#### Dependency Parsing
##### Faster than CFG-based Parsing
##### Captures Relations for Applications

### Partial Parsing / Chunking
#### Motivations for Parsing
##### Intermediate Step in Processing
##### Often Provides More Information Than Needed
#### Chunking
##### Goal: Divide Sentence into Chunks
##### Characteristics of Chunks
##### Nonexhaustive Text Grouping
#### Chunk Parsing: Accuracy
##### Smaller Solution Space
##### Better Locality
##### Less Error Propagation
#### Chunk Parsing: Domain Independence
##### Dependencies at Higher Level than Chunks
#### Chunk Parsing: Efficiency
##### Implemented with Finite State Automaton
##### Applicable to Large Text Sources

### Chunk Parsing in NLTK
#### Chunking with Regular Expressions
##### Tag Patterns in Chunk Rules
###### Define NP Chunk Rules
###### Parsing Tag Strings
##### Overlapping Rules
###### Leftmost Match Takes Precedence
##### More Chunking Rules: Chinking
###### Chink: sequence of stop words
###### Chinking: process of removing a sequence of tokens from a chunk delimited by square brackets.
###### A chink rule chinks anything that matches a given tag pattern.

#### Representing Chunks: IOB Tags vs Trees
##### Tagging Tokens with BEGIN, INSIDE, OUTSIDE
##### Example IOB Tags for NP

### Evaluating Chunk Parsers
#### Evaluation Phases
##### Compare Behavior Against a Standard
#### Precision/Recall/F
##### Precision: Percentage of Correct Chunks
##### Recall: Percentage of Correct Chunks Guessed
##### F Measure: Harmonic Mean of Precision and Recall
#### Evaluation Metrics
##### Calculating Measures Based on Guessed and Correct Chunks

### Readings
#### Recommended Literature
##### "Speech and Language Processing" by Jurafsky & Martin
##### "Natural Language Processing with Python" by Bird, Klein, & Loper

## Week07_Lectures 19-20

### NLP Evaluation
#### Importance of Evaluation
##### Decide which system is best for domain
##### Trustworthiness of the model
##### Points of Improvement
#### Types of Evaluation
##### Automatic Evaluation
###### Cost and repeatability
###### Challenges due to inter-annotator agreement
##### Manual Evaluation
###### Human judges
###### Subjectivity vs. Objectivity
##### Intrinsic Evaluation
###### Isolated system performance
##### Extrinsic Evaluation
###### System in complex setting
##### Black-box Evaluation
###### Global function between input and output
##### Glass-box Evaluation
###### Examines system's internals

### Evaluation Metrics
#### Accuracy
##### Simplest metric
##### Impact of test data
#### Precision and Recall
##### Used in information retrieval
##### True positives/negatives, False positives/negatives
##### F-Measure
#### Confusion Matrix
##### Tabular form of system's correctness
##### Diagonal and non-diagonal error analysis
#### Cross-Validation
##### K-folds method
##### Ensures no data is wasted
#### BLEU
##### Evaluating machine translation quality
##### Comparison with human translation
##### Unigram precision method
##### Modified precision for better scoring

### NLP Evaluation in Python
#### Python and Training/Test Sets
##### Random shuffle
##### Test on unseen data
#### Python and Evaluation Metrics
##### Accuracy with nltk.classify.accuracy
##### Confusion Matrix generation
##### Use of nltk.tag for tagging evaluation


## Week07_Lectures 21

### Machine Translation (MT)
#### Brief History
##### WWII to 1949: Inception and Weaver's Suggestion
##### 1954: Georgetown-IBM Experiment
##### 1975-1989: Increased Interest and AI Methods
##### 1990-2000: Commercial Products and Spoken Language Translation
##### 2000-Present: Statistical Approaches, Google Engine, Annual Evaluations
#### Importance of MT
##### Cost Efficiency and Globalization
##### Relevancy of Various Language Pairs
##### Varying Quality Acceptance Levels
#### MT Systems
##### Degree of Automation
###### MAHT, HAMT, FAMT
##### Number of Languages
###### Bilingual: Unidirectional & Bidirectional
###### Multilingual
##### Degree of Intervention
###### Non-interventionist (Batch) Mode
###### Interactive (Online) Mode
##### Domain Dependency
###### Limited Subject Field
###### General or Unrestricted Text

### The Translation Process
#### Translation Complexity
##### Beyond Word-for-Word Substitution
##### Necessity of Grammar, Syntax, and Semantics Expertise

### MT Approaches
#### Direct Translation
##### Characteristics and Model
##### Primitive Methods and Limited Use
#### Rule-Based
##### Concept and Types
###### Interlingua Approach
###### Transfer Approach
#### Corpus-Based
##### Statistical and Example-based Methods
##### Dependency on Aligned Texts and Reference Translations
#### Rule-Based vs Statistical MT
##### Comparison of Approaches
##### Third Approach Necessity

### Moses
#### Introduction to Moses
##### Features and Decoding
##### Supported Translation Models and Experiment Management
#### Getting Started with Moses
##### Retrieving Software
##### Training and Tuning Models
#### Moses Demos
##### Language Pairs and Interfaces

### Summary
#### Key Takeaways
##### Historical Development of MT
##### MT Relevance in Modern Context
##### Overview of MT Processing Approaches
##### Brief on Rule-Based vs Statistical MT
##### Introduction to Moses Tool

### Readings
#### Recommended Literature and Resources
##### Harold Somers' "Machine Translation"
##### Academic and Technical Slides
##### Moses Official Website


## Week08_Lectures 22-24

### Information Extraction
#### What is Information Extraction?
##### Automatic extraction of structured information
##### Transformation of unstructured/semi-structured data
#### Motivation
##### Exponential growth of electronic data
##### Need to automate the extraction process
#### Information Extraction Systems
##### Goal: Find and link relevant information
##### Should be easily modifiable and performant
#### Information Extraction Tasks
##### Named Entity Recognition
##### Co-reference Resolution
##### Template Element Construction
##### Template Relation Construction
##### Scenario Template Production
#### Why is Information Extraction difficult?
##### Variety of expression
##### Need to combine information across sentences
#### Information Extraction Generations
##### MUC - Message Understanding Conference

### Named Entity Recognition (NER)
#### What are Named Entities?
##### Identification and classification of proper names
#### What are NOT NEs
##### Artifacts, common nouns, etc.
#### NER Approaches
##### Rule-based using patterns
##### Machine Learning with annotated data
#### NLTK and NER
##### Utilizes nltk.ne_chunk()
##### Can tag as binary (NE) or with category labels

### GATE (General Architecture for Text Engineering)
#### Installation
##### Download from the official website
##### Compatible with multiple OS
#### ANNIE
##### Core components of a vanilla information extraction system
#### Gazetteer lists for rule-based NE
##### Indicator strings for internal structure and context rules
#### The Named Entity Grammars
##### Hand-coded rules to identify NEs

### Machine Learning Approaches to NER
#### Supervised Learning
##### Utilizes labeled training examples
##### Techniques like HMMs, SVM, Decision Trees, etc.
#### Unsupervised Learning
##### Discovers labels automatically
##### Method: clustering
#### Semi-supervised Learning
##### Combines labeled and unlabeled data
##### Techniques like bootstrapping, co-training, etc.

### NLTK and NER
#### NLTK's NER Classifier
##### Pre-trained classifier in NLTK
##### Binary and category label tagging options
#### NLTK's Category Labels
##### Labels such as PERSON, ORGANIZATION, GPE
#### NLTK NER Examples
##### Demonstrations of NLTK's ne_chunk function in use

### Readings
#### Suggested Material
##### "Speech and Language Processing" by Daniel Jurafsky & James H. Martin
##### "Natural Language Processing with Python" by Steven Bird, Ewan Klein, & Edward Loper
#### Additional Resources
##### GATE Tutorials
##### Named entity recognition demo from the University of Illinois
